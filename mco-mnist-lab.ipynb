{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mco-mnist-lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "Lvo0t7XVIkWZ",
        "qpiJj8ym0v0-",
        "SVY1pBg5ydH-"
      ],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcacohen/alpha-zero/blob/master/mco-mnist-lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-V89C6XrV3N",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcacohen/colabs/blob/master/mco-mnist_lab.ipynb)&nbsp;&nbsp;&nbsp;&nbsp;<a target=\"_blank\" href=\"https://colab.research.google.com/github/marcacohen/colabs/blob/master/mco_mnist_lab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xqLjB2cy5S7m"
      },
      "source": [
        "# Build a Digit Classification model on a Google TPU Using Keras and TensorFlow\n",
        "<table><tr><td><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/keras-tensorflow-tpu300px.png\" width=\"300\" alt=\"Keras+Tensorflow+Cloud TPU\"></td></tr></table>\n",
        "\n",
        "\n",
        "**This lab is derived from Martin Gorner's excellent, comprehensive, and highly recommended [Learn TensorFlow and deep learning, without a Ph.D.](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd) series.**\n",
        "\n",
        "This lab trains and evaluates a handwritten digit classification model using the MNIST dataset. It uses a Google Tensor Processing Unit (TPU) to speed up\n",
        "training and includes an interactive component that lets you test your model by drawing your own digits right inside this notebook.\n",
        "This notebook is provided for educational purposes only.\n",
        "\n",
        "Here's what we'll do in this lab:\n",
        "\n",
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>&nbsp;&nbsp; Train on TPU</h3>\n",
        "\n",
        "  1. Select a TPU backend (Runtime > Change runtime type) \n",
        "\n",
        "<h3><a href=\"https://www.tensorflow.org/js\"><img valign=\"middle\" src=\"data:image/png;base64,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\" width=\"50\"></a>&nbsp;&nbsp; Test our model interactively with TensorFlow.js</h3>\n",
        "\n",
        "  1. Export our model for use in JavaScript and run an interactive web app to test the model interactively, with hand drawn digits.\n",
        "\n",
        "<h3><a href=\"https://cloud.google.com/ml-engine/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/mlengine-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Deploy to ML Engine</h3>\n",
        "\n",
        "  1. At the bottom of this notebook you can deploy your trained model to ML Engine for a serverless, autoscaled, REST API experience. You will need a GCP project and a GCS bucket for this last part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lvo0t7XVIkWZ"
      },
      "source": [
        "## Parameters\n",
        "\n",
        "These are global variables that allow to specify invariant constants that are useful throughout this lab. In particular, we'll specify things like the batch size and number of epochs (iterations through our training data), as well as URLs to our training and validation data. If you've never seen URLs of the form gs://, those are paths to objects in [Google Cloud Storage](http://cloud.google.com/storage)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cCpkS9C_H7Tl",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128 # On TPU, this will be the per-core batch size. A Cloud TPU has 8 cores so the global TPU batch size is 1024\n",
        "EPOCHS = 10\n",
        "\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbi1K7DeNnQ7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qpiJj8ym0v0-"
      },
      "source": [
        "## Imports\n",
        "These are Python modules we'll need throughout this lab, including TensorFlow, which is Google's open source framework for graph computation. The latter dependency is so critical to this lab that we also display the version of TensorFlow we're importing into this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoilhmYe1b5t",
        "outputId": "88744810-d5ac-44c1-a05c-cdfae5334488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os, re, math, json, shutil, pprint\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import IPython.display as display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.platform import tf_logging\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhwDVKf_OEpd",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions\n",
        "This section contains two collections of Python utility functions, which are required for proper execution but not critical for understanding the main ideas or the flow of this notebook. As such, both cells need to be executed but the contents are hidden. If you really want to understand every step along the way, feel free to unhide those cells and have a look at these utility functions. One of the nice things about working in Python is the code tends to be quite readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV6i4Hbtf0hC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Data Visualization Utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.ioff()\n",
        "plt.rc('image', cmap='gray_r')\n",
        "plt.rc('grid', linewidth=1)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0', figsize=(16,9))\n",
        "# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "  \n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  batch_train_ds = training_dataset.apply(tf.data.experimental.unbatch()).batch(N)\n",
        "  \n",
        "  # eager execution: loop through datasets normally\n",
        "  if tf.executing_eagerly():\n",
        "    for validation_digits, validation_labels in validation_dataset:\n",
        "      validation_digits = validation_digits.numpy()\n",
        "      validation_labels = validation_labels.numpy()\n",
        "      break\n",
        "    for training_digits, training_labels in batch_train_ds:\n",
        "      training_digits = training_digits.numpy()\n",
        "      training_labels = training_labels.numpy()\n",
        "      break\n",
        "    \n",
        "  else:\n",
        "    v_images, v_labels = validation_dataset.make_one_shot_iterator().get_next()\n",
        "    t_images, t_labels = batch_train_ds.make_one_shot_iterator().get_next()\n",
        "    # Run once, get one batch. Session.run returns numpy results\n",
        "    with tf.Session() as ses:\n",
        "      (validation_digits, validation_labels,\n",
        "       training_digits, training_labels) = ses.run([v_images, v_labels, t_images, t_labels])\n",
        "  \n",
        "  # these were one-hot encoded in the dataset\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  training_labels = np.argmax(training_labels, axis=1)\n",
        "  \n",
        "  return (training_digits, training_labels,\n",
        "          validation_digits, validation_labels)\n",
        "\n",
        "# create digits from local fonts for testing\n",
        "def create_digits_from_local_fonts(n):\n",
        "  font_labels = []\n",
        "  img = PIL.Image.new('LA', (28*n, 28), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
        "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "  d = PIL.ImageDraw.Draw(img)\n",
        "  for i in range(n):\n",
        "    font_labels.append(i%10)\n",
        "    d.text((7+i*28,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
        "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
        "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [28, 28*n]), n, axis=1), axis=0), [n, 28*28])\n",
        "  return font_digits, font_labels\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits(digits, predictions, labels, title, n):\n",
        "  fig = plt.figure(figsize=(13,3))\n",
        "  digits = np.reshape(digits, [n, 28, 28])\n",
        "  digits = np.swapaxes(digits, 0, 1)\n",
        "  digits = np.reshape(digits, [28, 28*n])\n",
        "  plt.yticks([])\n",
        "  plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "  plt.grid(b=None)\n",
        "  for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "    if predictions[i] != labels[i]: t.set_color('red') # bad predictions in red\n",
        "  plt.imshow(digits)\n",
        "  plt.grid(None)\n",
        "  plt.title(title)\n",
        "  display.display(fig)\n",
        "  \n",
        "# utility to display multiple rows of digits, sorted by unrecognized/recognized status\n",
        "def display_top_unrecognized(digits, predictions, labels, n, lines):\n",
        "  idx = np.argsort(predictions==labels) # sort order: unrecognized first\n",
        "  for i in range(lines):\n",
        "    display_digits(digits[idx][i*n:(i+1)*n], predictions[idx][i*n:(i+1)*n], labels[idx][i*n:(i+1)*n],\n",
        "                   \"{} sample validation digits out of {} with bad predictions in red and sorted first\".format(n*lines, len(digits)) if i==0 else \"\", n)\n",
        "\n",
        "def plot_learning_rate(lr_func, epochs):\n",
        "  xx = np.arange(epochs+1, dtype=np.float)\n",
        "  y = [lr_decay(x) for x in xx]\n",
        "  fig, ax = plt.subplots(figsize=(9, 6))\n",
        "  ax.set_xlabel('epochs')\n",
        "  ax.set_title('Learning rate\\ndecays from {:0.3g} to {:0.3g}'.format(y[0], y[-2]))\n",
        "  ax.minorticks_on()\n",
        "  ax.grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "  ax.grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "  ax.step(xx,y, linewidth=3, where='post')\n",
        "  display.display(fig)\n",
        "  \n",
        "# utility to display training and validation curves\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(16, 7))\n",
        "  ax.grid(linewidth=1, color='white')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])\n",
        "  display.display(fig)\n",
        "\n",
        "class PlotTraining(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, sample_rate=1, zoom=1):\n",
        "    self.sample_rate = sample_rate\n",
        "    self.step = 0\n",
        "    self.zoom = zoom\n",
        "    self.steps_per_epoch = 60000//BATCH_SIZE\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.batch_history = {}\n",
        "    self.batch_step = []\n",
        "    self.epoch_history = {}\n",
        "    self.epoch_step = []\n",
        "    self.fig, self.axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "    plt.ioff()\n",
        "\n",
        "  def on_batch_end(self, batch, logs={}):\n",
        "    if (batch % self.sample_rate) == 0:\n",
        "      self.batch_step.append(self.step)\n",
        "      for k,v in logs.items():\n",
        "        # do not log \"batch\" and \"size\" metrics that do not change\n",
        "        # do not log training accuracy \"acc\"\n",
        "        if k=='batch' or k=='size':# or k=='acc':\n",
        "          continue\n",
        "        self.batch_history.setdefault(k, []).append(v)\n",
        "    self.step += 1\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    plt.close(self.fig)\n",
        "    self.axes[0].cla()\n",
        "    self.axes[1].cla()\n",
        "      \n",
        "    self.axes[0].set_ylim(0, 1.2/self.zoom)\n",
        "    self.axes[1].set_ylim(1-1/self.zoom/2, 1+0.1/self.zoom/2)\n",
        "    \n",
        "    self.epoch_step.append(self.step)\n",
        "    for k,v in logs.items():\n",
        "      # only log validation metrics\n",
        "      if not k.startswith('val_'):\n",
        "        continue\n",
        "      self.epoch_history.setdefault(k, []).append(v)\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    \n",
        "    for k,v in self.batch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.batch_step) / self.steps_per_epoch, v, label=k)\n",
        "      \n",
        "    for k,v in self.epoch_history.items():\n",
        "      self.axes[0 if k.endswith('loss') else 1].plot(np.array(self.epoch_step) / self.steps_per_epoch, v, label=k, linewidth=3)\n",
        "      \n",
        "    self.axes[0].legend()\n",
        "    self.axes[1].legend()\n",
        "    self.axes[0].set_xlabel('epochs')\n",
        "    self.axes[1].set_xlabel('epochs')\n",
        "    self.axes[0].minorticks_on()\n",
        "    self.axes[0].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[0].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    self.axes[1].minorticks_on()\n",
        "    self.axes[1].grid(True, which='major', axis='both', linestyle='-', linewidth=1)\n",
        "    self.axes[1].grid(True, which='minor', axis='both', linestyle=':', linewidth=0.5)\n",
        "    display.display(self.fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZE8dgyPC1_6m",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Dataset Processing Utilities [RUN ME] \n",
        "\"\"\"\n",
        "This cell contains helper functions used for parsing files and preparing\n",
        "training and validation datasets. See https://www.tensorflow.org/guide/performance/datasets\n",
        "for best practices for building input pipelines with tf.data.Dataset.\n",
        "\"\"\"\n",
        "\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.repeat() # Mandatory for Keras for now\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)\n",
        "\n",
        "# For TPU, we will need a function that returns the dataset\n",
        "# training_input_fn = lambda: get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "# validation_input_fn = lambda: get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_fXo6GuvL3EB"
      },
      "source": [
        "### Let's have a look at the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZ4tjPKvL2eh",
        "colab": {}
      },
      "source": [
        "N = 24\n",
        "(training_digits, training_labels,\n",
        " validation_digits, validation_labels) = dataset_to_numpy_util(training_dataset, validation_dataset, N)\n",
        "display_digits(training_digits, training_labels, training_labels, \"training digits and their labels\", N)\n",
        "display_digits(validation_digits[:N], validation_labels[:N], validation_labels[:N], \"validation digits and their labels\", N)\n",
        "font_digits, font_labels = create_digits_from_local_fonts(N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsvlAnHxl4UO",
        "colab_type": "text"
      },
      "source": [
        "### First Try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TXBlVVCl7-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "  [\n",
        "      tf.keras.layers.Input(shape=(28*28,)),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()\n",
        "\n",
        "# utility callback that displays training curves\n",
        "plot_training = PlotTraining(sample_rate=10, zoom=1)\n",
        "\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1, callbacks=[plot_training])\n",
        "\n",
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KIc0oqiD40HC"
      },
      "source": [
        "### A better model: 3 convolutional layers, 2 dense layers\n",
        "If you are not sure what cross-entropy, dropout, softmax or batch-normalization mean, head here for a crash-course: [Tensorflow and deep learning without a PhD](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/#featured-code-sample)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "56y8UNFQIVwj",
        "colab": {}
      },
      "source": [
        "# This model trains to 99.4%— sometimes 99.5%— accuracy in 10 epochs (with a batch size of 32)\n",
        "\n",
        "def create_model():\n",
        "  return tf.keras.Sequential(\n",
        "    [\n",
        "      tf.keras.layers.Reshape(input_shape=(28*28,), target_shape=(28, 28, 1)),\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=6, kernel_size=3, padding='same', use_bias=False), # no bias necessary before batch norm\n",
        "      tf.keras.layers.BatchNormalization(scale=False, center=True), # no batch norm scaling necessary before \"relu\"\n",
        "      tf.keras.layers.Activation('relu'), # activation after batch norm\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=12, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "      tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2),\n",
        "      tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(200, use_bias=False),\n",
        "      tf.keras.layers.BatchNormalization(scale=False, center=True),\n",
        "      tf.keras.layers.Activation('relu'),\n",
        "      tf.keras.layers.Dropout(0.5), # Dropout on dense layer only\n",
        "\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDWtnyIMh0Xc",
        "colab_type": "text"
      },
      "source": [
        "### Compile, train, and validate model on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-Ymf5nuiEQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print model layers\n",
        "model.summary()\n",
        "\n",
        "# setup inter-epoch results plotter\n",
        "plot_training = PlotTraining(sample_rate=10, zoom=1)\n",
        "\n",
        "# set up learning rate decay\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0001 + 0.02 * math.pow(0.5, 1+epoch), verbose=True)\n",
        "\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "\n",
        "# Counting steps and batches on TPU: the tpu.keras_to_tpu_model API regards the batch size of the input dataset\n",
        "# as the per-core batch size. The effective batch size is 8x more because Cloud TPUs have 8 cores. It increments\n",
        "# the step by +8 everytime a global batch (8 per-core batches) is processed. Therefore batch size and steps_per_epoch\n",
        "# settings can stay as they are for TPU training. The training will just go faster.\n",
        "# Warning: this might change in the final version of the Keras/TPU API.\n",
        "\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay, plot_training])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLpc2B-oUL_E",
        "colab_type": "text"
      },
      "source": [
        "**STOP!!! THIS IS TOO PAINFUL.\n",
        "Let's try this on a TPU...**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CuhDh8ao8VyB"
      },
      "source": [
        "### Compile, train, and validate the model on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocb9579DQMFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(optimizer='adam', # learning rate will be set by LearningRateScheduler\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "  plot_training = PlotTraining(sample_rate=10, zoom=1)\n",
        "  lr_decay = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0001 + 0.02 * math.pow(0.5, 1+epoch), verbose=True)\n",
        "\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "\n",
        "# Counting steps and batches on TPU: the tpu.keras_to_tpu_model API regards the batch size of the input dataset\n",
        "# as the per-core batch size. The effective batch size is 8x more because Cloud TPUs have 8 cores. It increments\n",
        "# the step by +8 everytime a global batch (8 per-core batches) is processed. Therefore batch size and steps_per_epoch\n",
        "# settings can stay as they are for TPU training. The training will just go faster.\n",
        "# Warning: this might change in the final version of the Keras/TPU API.\n",
        "\n",
        "history = model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1, callbacks=[lr_decay, plot_training])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9jFVovcUUVs1"
      },
      "source": [
        "### Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w12OId8Mz7dF",
        "colab": {}
      },
      "source": [
        "# recognize digits from local fonts\n",
        "probabilities = model.predict(font_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_digits(font_digits, predicted_labels, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "probabilities = model.predict(validation_digits, steps=1)\n",
        "predicted_labels = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_kBGkerzrss",
        "colab_type": "text"
      },
      "source": [
        "### Save model and prep for use by TF.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIBlNXQ6zxdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('mnist.h5')\n",
        "!pip install tensorflowjs \n",
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras mnist.h5 model/\n",
        "!zip -r model.zip model \n",
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5tzVi39ShrEL"
      },
      "source": [
        "## Deploy the trained model to ML Engine\n",
        "\n",
        "Push your trained model to production on ML Engine for a serverless, autoscaled, REST API experience.\n",
        "\n",
        "You will need a GCS bucket and a GCP project for this.\n",
        "Models deployed on ML Engine autoscale to zero if not used. There will be no ML Engine charges after you are done testing.\n",
        "Google Cloud Storage incurs charges. Empty the bucket after deployment if you want to avoid these. Once the model is deployed, the bucket is not useful anymore."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lzd6Qi464PsA"
      },
      "source": [
        "### Authentication for TPU Access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "MPx0nvyUnvgT",
        "colab": {}
      },
      "source": [
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user() # Authenticates the backend and also the TPU using your credentials so that they can access your private GCS buckets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Y3ztMY_toCP"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "iAZAn7yIhqAS",
        "colab": {}
      },
      "source": [
        "PROJECT = \"\" #@param {type:\"string\"}\n",
        "BUCKET = \"gs://\"  #@param {type:\"string\", default:\"jddj\"}\n",
        "NEW_MODEL = True #@param {type:\"boolean\"}\n",
        "MODEL_NAME = \"colabmnist\" #@param {type:\"string\"}\n",
        "MODEL_VERSION = \"v0\" #@param {type:\"string\"}\n",
        "\n",
        "assert PROJECT, 'For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one.'\n",
        "assert re.search(r'gs://.+', BUCKET), 'For this part, you need a GCS bucket. Head to http://console.cloud.google.com/storage and create one.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GxQTtjmdIbmN"
      },
      "source": [
        "### Export the model for serving from ML Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMv5ZEuHPU7W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GOgh7Kb7SzzG",
        "colab": {}
      },
      "source": [
        "class ServingInput(tf.keras.layers.Layer):\n",
        "  # the important detail in this boilerplate code is \"trainable=False\"\n",
        "  def __init__(self, name, dtype, batch_input_shape=None):\n",
        "    super(ServingInput, self).__init__(trainable=False, name=name, dtype=dtype, batch_input_shape=batch_input_shape)\n",
        "  def get_config(self):\n",
        "    return {'batch_input_shape': self._batch_input_shape, 'dtype': self.dtype, 'name': self.name }\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # When the deployed model is called through its REST API,\n",
        "    # the JSON payload is parsed automatically, transformed into\n",
        "    # a tensor and passed to this input layer. You can perform\n",
        "    # additional transformations, such as decoding JPEGs for example,\n",
        "    # before sending the data to your model. However, you can only\n",
        "    # use tf.xxxx operations.\n",
        "    return inputs\n",
        "\n",
        "# little wrinkle: must copy the model from TPU to CPU manually. This is a temporary workaround.\n",
        "tf_logging.set_verbosity(tf_logging.INFO)\n",
        "restored_model = model\n",
        "restored_model.set_weights(train_model.get_weights()) # this copied the weights from TPU, does nothing on GPU\n",
        "tf_logging.set_verbosity(tf_logging.WARN)\n",
        "\n",
        "# add the serving input layer\n",
        "serving_model = tf.keras.Sequential()\n",
        "serving_model.add(ServingInput('serving', tf.float32, (None, 28*28)))\n",
        "serving_model.add(restored_model)\n",
        "export_path = tf.contrib.saved_model.save_keras_model(serving_model, os.path.join(BUCKET, 'keras_export'))  # export he model to your bucket\n",
        "export_path = export_path.decode('utf-8')\n",
        "print(\"Model exported to: \", export_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zy3T3zk0u2J0"
      },
      "source": [
        "### Deploy the model\n",
        "This uses the command-line interface. You can do the same thing through the ML Engine UI at https://console.cloud.google.com/mlengine/models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGv3ITiGLPL3",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "if NEW_MODEL:\n",
        "  !gcloud ai-platform models create {MODEL_NAME} --project={PROJECT} --regions=us-central1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o3QtUowtOAL-",
        "colab": {}
      },
      "source": [
        "# Create a version of this model (you can add --async at the end of the line to make this call non blocking)\n",
        "# Additional config flags are available: https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions\n",
        "# You can also deploy a model that is stored locally by providing a --staging-bucket=... parameter\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "!gcloud ai-platform versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version=1.10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jE-k1Zn6kU2Z"
      },
      "source": [
        "### Test the deployed model\n",
        "Your model is now available as a REST API. Let us try to call it. The cells below use the \"gcloud ml-engine\"\n",
        "command line tool but any tool that can send a JSON payload to a REST endpoint will work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZCt0Ke2QDer",
        "colab": {}
      },
      "source": [
        "# prepare digits to send to online prediction endpoint\n",
        "digits = np.concatenate((font_digits, validation_digits[:100-N]))\n",
        "labels = np.concatenate((font_labels, validation_labels[:100-N]))\n",
        "with open(\"digits.json\", \"w\") as f:\n",
        "  for digit in digits:\n",
        "    # the format for ML Engine online predictions is: one JSON object per line\n",
        "    data = json.dumps({\"serving_input\": digit.tolist()})  # \"serving_input\" because the ServingInput layer was named \"serving\". Keras appends \"_input\"\n",
        "    f.write(data+'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n6PqhQ8RQ8bp",
        "colab": {}
      },
      "source": [
        "# Request online predictions from deployed model (REST API) using the \"gcloud ml-engine\" command line.\n",
        "predictions = !gcloud ai-platform predict --model={MODEL_NAME} --json-instances digits.json --project={PROJECT} --version {MODEL_VERSION}\n",
        "print(predictions)\n",
        "\n",
        "probabilities = np.stack([json.loads(p) for p in predictions[1:]]) # first line is the name of the input layer: drop it, parse the rest\n",
        "predictions = np.argmax(probabilities, axis=1)\n",
        "display_top_unrecognized(digits, predictions, labels, N, 100//N)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SVY1pBg5ydH-"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hleIN5-pcr0N"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "author: Martin Gorner<br>\n",
        "twitter: @martin_gorner\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Copyright 2018 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose\n"
      ]
    }
  ]
}